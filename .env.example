# ============================================
# DCYFR AI Agents - Configuration
# ============================================
# Copy this file to .env and fill in your values
# Required for running examples and autonomous agent demonstrations

# ============================================
# LLM Provider Configuration
# ============================================
# Choose one or more providers for agent execution

# --- Option 1: Msty Vibe CLI Proxy (Recommended for Development) ---
# Multi-model routing: Claude, GPT-4, Copilot, Gemini, and more
# Start Msty Studio with Vibe CLI Proxy enabled (default: http://localhost:8317)
# Docs: https://docs.msty.studio/features/vibe-cli-proxy
# OPENAI_API_BASE=http://localhost:8317/v1
# OPENAI_API_KEY=msty-vibe-proxy  # Any non-empty value

# --- Option 2: OpenAI Direct ---
# Direct OpenAI API access for production workloads
OPENAI_API_KEY=

# --- Option 3: Anthropic Direct ---
# Direct Anthropic API access for Claude models
# ANTHROPIC_API_KEY=

# --- Option 4: Ollama (Local) ---
# Local LLM inference for offline development
# OLLAMA_URL=http://localhost:11434

# ============================================
# Memory Configuration (Optional)
# ============================================
# Required for examples using memory features

# Vector database provider
VECTOR_DB_PROVIDER=qdrant

# Qdrant configuration (local development)
VECTOR_DB_URL=http://localhost:6333
VECTOR_DB_INDEX=dcyfr_memories

# LLM for memory embeddings
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
LLM_EMBEDDING_MODEL=text-embedding-3-small

# ============================================
# Telemetry Configuration (Optional)
# ============================================
# Required for telemetry dashboard and cost tracking

# Enable telemetry collection (default: true)
TELEMETRY_ENABLED=true

# Telemetry storage (memory, sqlite, upstash)
TELEMETRY_STORAGE=sqlite

# Upstash Redis (for production telemetry)
# UPSTASH_REDIS_REST_URL=
# UPSTASH_REDIS_REST_TOKEN=

# ============================================
# Version Detection
# ============================================

# DCYFR Agents version (for compatibility checking)
DCYFR_AGENTS_VERSION=1.0.0

# ============================================
# Development & Testing
# ============================================

# Enable debug logging
# DEBUG=dcyfr:*

# Node environment
NODE_ENV=development

# ============================================
# Example-Specific Configuration
# ============================================

# Autonomous Research Agent
# Maximum research depth (number of research steps)
RESEARCH_MAX_DEPTH=5

# Customer Service Agent
# Default response timeout (ms)
CS_RESPONSE_TIMEOUT=30000

# Code Generator Agent
# Target language/framework
CODEGEN_TARGET=typescript

# ============================================
# Quick Start Configurations
# ============================================
#
# üöÄ Minimal Setup (Msty Vibe):
# OPENAI_API_BASE=http://localhost:8317/v1
# OPENAI_API_KEY=msty-vibe-proxy
#
# üåê Production Setup:
# OPENAI_API_KEY=sk-proj-...
# VECTOR_DB_PROVIDER=qdrant
# VECTOR_DB_URL=http://localhost:6333
# TELEMETRY_STORAGE=upstash
# UPSTASH_REDIS_REST_URL=https://...
# UPSTASH_REDIS_REST_TOKEN=...
#
# üîí Offline Setup (Ollama):
# OLLAMA_URL=http://localhost:11434
# VECTOR_DB_PROVIDER=qdrant
# VECTOR_DB_URL=http://localhost:6333
# TELEMETRY_STORAGE=sqlite
#
# ============================================

# ============================================
# Getting Started
# ============================================
#
# 1. Copy this file: cp .env.example .env
#
# 2. Choose a provider configuration (see Quick Start above)
#
# 3. Start required services:
#    - Qdrant: docker run -p 6333:6333 qdrant/qdrant
#    - Msty Vibe: Start Msty Studio with Vibe CLI Proxy enabled
#    - Ollama: ollama serve
#
# 4. Run examples:
#    cd examples/autonomous-research-agent
#    npm run demo
#
# 5. View telemetry:
#    npx @dcyfr/ai telemetry
#
# For detailed setup instructions, see:
# - ../dcyfr-ai/docs/PROVIDER_INTEGRATIONS.md
# - examples/autonomous-research-agent/README.md
#
# ============================================
